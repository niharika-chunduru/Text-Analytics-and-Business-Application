{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/Patron/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   stars        100000 non-null  float64\n",
      " 1   useful       100000 non-null  int64  \n",
      " 2   text         100000 non-null  object \n",
      " 3   funny        100000 non-null  int64  \n",
      " 4   review_id    100000 non-null  object \n",
      " 5   cool         100000 non-null  int64  \n",
      " 6   date         100000 non-null  object \n",
      " 7   user_id      100000 non-null  object \n",
      " 8   business_id  100000 non-null  object \n",
      "dtypes: float64(1), int64(3), object(5)\n",
      "memory usage: 6.9+ MB\n"
     ]
    }
   ],
   "source": [
    "yelp = pd.read_csv(\"yelp_review.csv\")\n",
    "yelp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    First time waxing. I read all the other review...\n",
       "1    I love my manicure! Such an affordable place. ...\n",
       "2    Great food, fast service, they try to crank pe...\n",
       "3    Save your money and go across the street the f...\n",
       "4    Oops...this was for the Main St location:\\n\\n-...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp.text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    first time waxing. i read all the other review...\n",
       "1    i love my manicure! such an affordable place. ...\n",
       "2    great food, fast service, they try to crank pe...\n",
       "3    save your money and go across the street the f...\n",
       "4    oops...this was for the main st location:\\n\\n-...\n",
       "Name: text_lower, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change all text into lower-case\n",
    "yelp['text_lower'] = yelp.text.apply(lambda x:x.lower())\n",
    "yelp.text_lower.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    first time waxing. i read all the other review...\n",
       "1    i love my manicure! such an affordable place. ...\n",
       "2    great food, fast service, they try to crank pe...\n",
       "3    save your money and go across the street the f...\n",
       "4    oops...this was for the main st location:\\n\\n-...\n",
       "Name: text_lower_no_digits, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove digits\n",
    "text_lower_no_digits = []\n",
    "\n",
    "# Iterate over all letters in each word and replace all digits with an empty string\n",
    "for word in yelp.text_lower:\n",
    "    letters = [letter for letter in word if not letter.isdigit()]\n",
    "    text_lower_no_digits.append(''.join(letters))\n",
    "\n",
    "yelp['text_lower_no_digits'] = pd.Series(text_lower_no_digits)\n",
    "yelp.text_lower_no_digits.head()\n",
    "# yelp.iloc[22,:].text_lower_no_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    first time waxing i read all the other reviews...\n",
       "1    i love my manicure such an affordable place th...\n",
       "2    great food fast service they try to crank peop...\n",
       "3    save your money and go across the street the f...\n",
       "4    oopsthis was for the main st location\\n\\n\\n\\nw...\n",
       "Name: text_lower_no_digits_non_punct, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the punctuation\n",
    "text_lower_no_digits_non_punct = []\n",
    "\n",
    "# Iterate over all letters in each word and replace all punctuations with an empty string\n",
    "for word in yelp.text_lower_no_digits:\n",
    "    letters = [letter for letter in word if letter not in string.punctuation]\n",
    "    text_lower_no_digits_non_punct.append(''.join(letters))\n",
    "\n",
    "\n",
    "yelp['text_lower_no_digits_non_punct'] = pd.Series(text_lower_no_digits_non_punct)\n",
    "yelp.text_lower_no_digits_non_punct.head()\n",
    "# yelp.iloc[22,:].text_lower_no_digits_non_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:6: SyntaxWarning: invalid escape sequence '\\W'\n",
      "<>:6: SyntaxWarning: invalid escape sequence '\\W'\n",
      "/var/folders/qq/03sjdbt93vn87r2lrkqk8mb40000gq/T/ipykernel_28123/4241427428.py:6: SyntaxWarning: invalid escape sequence '\\W'\n",
      "  split_words = re.split(\"\\W+\",word)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    [first, time, waxing, i, read, all, the, other...\n",
       "1    [i, love, my, manicure, such, an, affordable, ...\n",
       "2    [great, food, fast, service, they, try, to, cr...\n",
       "3    [save, your, money, and, go, across, the, stre...\n",
       "4    [oopsthis, was, for, the, main, st, location, ...\n",
       "Name: text_lower_no_digits_non_punct_split, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenization\n",
    "\n",
    "tokens = []\n",
    "\n",
    "# Iterate over all reviews and split it into a list of words\n",
    "for review in yelp.text_lower_no_digits_non_punct:\n",
    "    split_words = re.split(\"\\W+\",review)\n",
    "    tokens.append([word.lower() for word in split_words])\n",
    "\n",
    "\n",
    "yelp['text_lower_no_digits_non_punct_split'] = pd.Series(tokens)\n",
    "yelp.text_lower_no_digits_non_punct_split.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [first, time, waxing, read, reviews, decided, ...\n",
       "1    [love, manicure, affordable, place, manicurist...\n",
       "2    [great, food, fast, service, try, crank, peopl...\n",
       "3    [save, money, go, across, street, food, way, b...\n",
       "4    [oopsthis, main, st, location, visited, aladdi...\n",
       "Name: text_lower_no_digits_non_punct_split_non_stopwords, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove stop words\n",
    "nltk_stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "stopwords = []\n",
    "\n",
    "# Iterate over each splitted review and remove all the stop words\n",
    "for review in yelp.text_lower_no_digits_non_punct_split:\n",
    "    non_stop = [word for word in review if word not in nltk_stopwords]\n",
    "    stopwords.append(non_stop)\n",
    "\n",
    "yelp['text_lower_no_digits_non_punct_split_non_stopwords'] = pd.Series(stopwords)\n",
    "yelp.text_lower_no_digits_non_punct_split_non_stopwords.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [first, time, wax, read, review, decid, trust,...\n",
       "1    [love, manicur, afford, place, manicurist, kin...\n",
       "2    [great, food, fast, servic, tri, crank, peopl,...\n",
       "3    [save, money, go, across, street, food, way, b...\n",
       "4    [oopsthi, main, st, locat, visit, aladdin, way...\n",
       "Name: text_lower_no_digits_non_punct_split_non_stopwords_stemmed, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmatize/Stem\n",
    "stemmed_list = []\n",
    "\n",
    "# Iterate over each splitted review and remove and stem every word to its root form\n",
    "for review in yelp['text_lower_no_digits_non_punct_split_non_stopwords']:\n",
    "    stemmed = [ps.stem(word) for word in review]\n",
    "    stemmed_list.append(stemmed)\n",
    "\n",
    "yelp['text_lower_no_digits_non_punct_split_non_stopwords_stemmed'] = pd.Series(stemmed_list)\n",
    "yelp.text_lower_no_digits_non_punct_split_non_stopwords_stemmed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List five words that got removed after removing stop words.\n",
    "\n",
    "+ all\n",
    "+ the\n",
    "+ other\n",
    "+ my\n",
    "+ such"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Please use two examples to briefly describe the purpose of ‘stemming’.\n",
    "\n",
    "Stemming produces morphological variants of root words. For example, `location` changes to `locat`, This helps in grouping the words for further analysis, because if a review contains the word `located`, it should should fall under the same word tree as `location`. Same goes for `try` and `tried`, which fall under the root `tr`. This helps in classifying text into related clusters which can eventually help in deriving sentiment of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store your pre-processed data in your Google Drive and name it as ‘yelp_review_cleaned.csv’\n",
    "yelp.to_csv(\"yelp_review_cleaned.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
